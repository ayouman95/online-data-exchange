#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import os
import json
import logging
import time
from datetime import datetime, timedelta
import pycountry
import gzip
from io import BytesIO
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

from qcloud_cos import CosConfig, CosS3Client
import oss2
import orjson


# ================== é…ç½®åŒº ==================
TENCENT_SECRET_ID = os.environ['COS_SECRET_ID']
TENCENT_SECRET_KEY = os.environ['COS_SECRET_KEY']
TENCENT_REGION_LIST = ['de', 'sg', 'us']
TENCENT_APPID = "1374116111"
COS_REGION_MAP = {
    'de': 'eu-frankfurt',
    'sg': 'ap-singapore',
    'us': 'na-siliconvalley'
}

# é˜¿é‡Œäº‘ OSS é…ç½®ï¼ˆè·¯å¾„æ—¶é—´åŸºäº UTC+0ï¼‰
ALI_ACCESS_KEY_ID = os.environ["OSS_ACCESS_KEY_ID"]
ALI_ACCESS_KEY_SECRET = os.environ["OSS_ACCESS_KEY_SECRET"]
ALI_OSS_ENDPOINT = "https://oss-ap-southeast-1.aliyuncs.com"  # æ›¿æ¢ä¸ºä½ å®é™…çš„ endpoint
ALI_BUCKET_NAME = "tracking-collect-data-test"  # TODO: æ”¹æˆå®é™…çš„

SIZE_LIMITS_MB = {
    ('android', 'idn'): 200,
    ('android', 'tha'): 100,
    ('android', 'phl'): 240,
    ('android', 'ita'): 15,
    ('android', 'pol'): 20,
    ('android', 'nld'): 20,
    ('android', 'bra'): 80,
    ('android', 'mex'): 150,
    ('android', 'zaf'): 20,
    ('android', 'kor'): 7,
    ('android', 'ukr'): 20,
    ('android', 'can'): 11,
    ('android', 'usa'): 40,
    ('android', 'esp'): 35,
    ('android', 'ind'): 75,
    ('android', 'sau'): 70,
    ('android', 'fra'): 50,
    ('android', 'gbr'): 20,
    ('android', 'deu'): 75,
    ('android', 'are'): 40,
    ('android', 'rus'): 200,
}

# å¹¶å‘é…ç½®
DOWNLOAD_WORKERS = 8   # ä¸‹è½½å¹¶å‘æ•°ï¼ˆå»ºè®® = CPU æ ¸æ•°ï¼‰
UPLOAD_WORKERS = 4     # ä¸Šä¼ å¹¶å‘æ•°

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
)
logger = logging.getLogger(__name__)


def country_2to3_lower(cc2):
    try:
        country = pycountry.countries.get(alpha_2=cc2)
        return country.alpha_3.lower() if country else "xxx"
    except Exception:
        return "xxx"


def get_time_ranges_for_previous_hour():
    now_utc = datetime.utcnow()
    prev_hour_utc = now_utc.replace(minute=0, second=0, microsecond=0) - timedelta(hours=1)

    # UTC+0 è¾“å‡ºè·¯å¾„ç”¨
    utc0_hour_dt = prev_hour_utc

    # UTC+8 ç”¨äºæ„å»ºè…¾è®¯ COS è·¯å¾„
    utc8_now = now_utc + timedelta(hours=8)
    utc8_prev_hour = utc8_now.replace(minute=0, second=0, microsecond=0) - timedelta(hours=1)

    return utc0_hour_dt, utc8_prev_hour


# ==== å…¨å±€ä¸Šä¼ çº¿ç¨‹æ±  ====
upload_executor = ThreadPoolExecutor(max_workers=UPLOAD_WORKERS)


# ==== é«˜æ€§èƒ½ä¸Šä¼ å™¨ ====
class BufferedUploader:
    def __init__(self, platform, geo3, limit_mb, oss_bucket, date_part, hour_part):
        self.platform = platform
        self.geo3 = geo3
        self.limit_bytes = limit_mb * 1024 * 1024 if limit_mb else None
        self.oss_bucket = oss_bucket
        self.date_part = date_part
        self.hour_part = hour_part

        self.buffer = BytesIO()
        self.gz_file = gzip.GzipFile(mode='wb', fileobj=self.buffer)
        self.current_size = 0
        self.line_count = 0
        self.lock = threading.Lock()
        self.uploaded = False

    def write(self, line: str):
        with self.lock:
            if self.uploaded:
                return

            line_bytes = (line + '\n').encode('utf-8')
            added_size = len(line_bytes)

            if self.limit_bytes and self.current_size + added_size > self.limit_bytes:
                self._submit_upload()  # è§¦å‘å¼‚æ­¥ä¸Šä¼ 
                return

            self.gz_file.write(line_bytes)
            self.current_size += added_size
            self.line_count += 1

    def _submit_upload(self):
        """æäº¤å¼‚æ­¥ä¸Šä¼ ä»»åŠ¡"""
        if self.line_count == 0 or self.uploaded:
            return

        self.gz_file.close()
        self.buffer.seek(0)
        content = self.buffer.read()

        upload_executor.submit(self._do_upload, content)

    def _do_upload(self, content: bytes):
        filename = f"{self.platform}.{self.geo3}.log.gz"
        key = f"track/{self.date_part}/{self.hour_part}/{filename}"
        try:
            self.oss_bucket.put_object(key, content)
            logger.info(f"âœ… ä¸Šä¼ å®Œæˆ: {key} ({self.line_count} è¡Œ)")
        except Exception as e:
            logger.error(f"âŒ ä¸Šä¼ å¤±è´¥ {key}: {e}")
        self.uploaded = True


# ==== ä¸»å‡½æ•° ====
def main():
    utc0_hour_dt, utc8_hour_dt = get_time_ranges_for_previous_hour()
    logger.info(f"UTC+8 æ—¶é—´æ®µ: {utc8_hour_dt.strftime('%Y-%m-%d %H:00')} (è¯»å–è…¾è®¯ COS)")
    logger.info(f"UTC+0 æ—¶é—´æ®µ: {utc0_hour_dt.strftime('%Y-%m-%d %H:00')} (å†™å…¥é˜¿é‡Œ OSS)")

    auth = oss2.Auth(ALI_ACCESS_KEY_ID, ALI_ACCESS_KEY_SECRET)
    bucket = oss2.Bucket(auth, ALI_OSS_ENDPOINT, ALI_BUCKET_NAME)

    date_part = utc0_hour_dt.strftime("%Y-%m-%d")
    hour_part = utc0_hour_dt.strftime("%H")

    # å…¨å±€ uploader ç¼“å­˜
    uploaders = {}
    uploader_lock = threading.Lock()

    def get_uploader(platform, geo3):
        key = (platform, geo3)
        if key not in uploaders:
            with uploader_lock:
                if key not in uploaders:  # double-check
                    limit_mb = SIZE_LIMITS_MB.get(key)
                    uploaders[key] = BufferedUploader(platform, geo3, limit_mb, bucket, date_part, hour_part)
        return uploaders[key]

    # ===== å¤šçº¿ç¨‹ä¸‹è½½æ‰€æœ‰æ–‡ä»¶ =====
    prefixes = build_cos_prefixes(utc8_hour_dt.strftime("%Y%m%d"), utc8_hour_dt.strftime("%H"))
    file_list = []

    for conf in prefixes:
        marker = ""
        while True:
            try:
                response = conf['client'].list_objects(
                    Bucket=conf['bucket'],
                    Prefix=conf['prefix'],
                    Marker=marker
                )
                contents = response.get('Contents', [])
                for item in contents:
                    if not item['Key'].endswith('/'):
                        file_list.append((conf['client'], conf['bucket'], item['Key']))
                if not response.get('isTruncated'):
                    break
                marker = response.get('NextMarker', "")
            except Exception as e:
                logger.error(f"åˆ—å‡ºå¤±è´¥: {conf['bucket']}/{conf['prefix']}: {e}")
                break

    logger.info(f"å‘ç° {len(file_list)} ä¸ªå¾…å¤„ç†æ–‡ä»¶ï¼Œå¯åŠ¨ {DOWNLOAD_WORKERS} ä¸ªä¸‹è½½çº¿ç¨‹...")

    def process_single_file(args):
        # TODO: å¦‚æœæ‰€æœ‰uploaderéƒ½å·²ä¸Šä¼ å®Œæˆï¼Œåˆ™ç»“æŸ
        if all(uploader.uploaded for uploader in uploaders.values()):
            logger.info("æ‰€æœ‰æ–‡ä»¶å·²å¤„ç†å®Œæ¯•ï¼Œç»“æŸä¸‹è½½çº¿ç¨‹...")
            return

        client, bucket_name, key = args
        line_count = 0
        try:
            stream = client.get_object(Bucket=bucket_name, Key=key)['Body'].get_raw_stream()
            for raw_line in stream:
                line = raw_line.strip().decode('utf-8')
                if not line:
                    continue
                try:
                    data = orjson.loads(line)
                    cc2 = data.get("country_code", "").strip().upper()
                    platform = data.get("platform", "").strip().lower()

                    # çŸ«æ­£å›½å®¶
                    if cc2 == "UK":
                        cc2 = "GB"
                    platform = data.get("platform", "").strip().lower()

                    if platform not in ["android", "ios"]:
                        continue

                    # å¦‚æœæ‰¾ä¸åˆ°ä¸‰ä½å›½å®¶ä»£ç ï¼Œåˆ™å¿½ç•¥
                    geo3 = country_2to3_lower(cc2)
                    if geo3 == 'xxx':
                        continue

                    # æ²¡æœ‰é™åˆ¶æ–‡ä»¶å¤§å°ï¼Œåˆ™å¿½ç•¥
                    if not SIZE_LIMITS_MB.get((platform, geo3)):
                        continue


                    geo3 = country_2to3_lower(cc2)
                    uploader = get_uploader(platform, geo3)

                    new_line = transform_line(data, geo3)
                    uploader.write(new_line)
                    line_count += 1
                except Exception:
                    pass
            logger.debug(f"å®Œæˆ: {key} ({line_count} è¡Œ)")
        except Exception as e:
            logger.error(f"å¤„ç†å¤±è´¥ {key}: {e}")
        return line_count

    total_lines = 0
    with ThreadPoolExecutor(max_workers=DOWNLOAD_WORKERS) as download_executor:
        futures = [download_executor.submit(process_single_file, file_args) for file_args in file_list]
        for future in as_completed(futures):
            total_lines += future.result()

    # ç­‰å¾…æ‰€æœ‰ä¸Šä¼ å®Œæˆ
    upload_executor.shutdown(wait=True)

    logger.info(f"ğŸ“Š å¤„ç†å®Œæˆï¼šå…± {len(file_list)} ä¸ªæ–‡ä»¶ï¼Œ{total_lines} æ¡æ—¥å¿—ã€‚")


def transform_line(data, geo3):
    os = data.get("platform", "")
    osi = 0
    if os == "android":
        osi = 2
    if os == "ios":
        osi = 1

    fields = [
        geo3.upper(),
        osi,
        data.get("display_manager", ""),
        data.get("deviceId", ""),
        data.get("brand", ""),
        data.get("user_agent", ""),
        data.get("ip", ""),
        data.get("language", ""),
        data.get("timestamp", ""),
        data.get("os_version", ""),
        data.get("app_id", ""),
        data.get("model", ""),
        data.get("network_type", "")
    ]

    # æ‹¼æ¥ä¸º @ åˆ†éš”å­—ç¬¦ä¸²
    output_line = "@".join(str(f) for f in fields)

    return output_line
def build_cos_prefixes(date_str, hour_str):
    prefixes = []
    for region in TENCENT_REGION_LIST:
        bucket_name = f"pando-adx-{region}-{TENCENT_APPID}"
        prefix = f"adx_device/request/{date_str}/{hour_str}/"
        region_cos = COS_REGION_MAP[region]
        config = CosConfig(Region=region_cos, SecretId=TENCENT_SECRET_ID, SecretKey=TENCENT_SECRET_KEY)
        client = CosS3Client(config)
        prefixes.append({'bucket': bucket_name, 'prefix': prefix, 'client': client})
    return prefixes


if __name__ == "__main__":
    # è®¡ç®—è€—æ—¶
    start_time = time.time()
    main()
    logger.info(f"è€—æ—¶: {time.time() - start_time} ç§’")